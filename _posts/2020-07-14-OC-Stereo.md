---
layout: post
title:  "OC-Stereo: Object-Centric Stereo Matching for 3D Object Detection"
date:   2020-07-14 18:00
categories: PaperReading 
tags: [3D Object Detection, Vision]
comments: true
toc: true
---

OC-Stereo 也是一种类似基于 Pseudo Lidar 的 3D 检测方法。不同在于，OC-Stereo通过 2D 的目标检测，仅在目标的 ROI 范围内进行视差的学习，并转换至点云空间进行 3D 检测。相类似的还有 Disp-RCNN，后续也会新增这篇论文的笔记。


## 主要贡献

* 基于左右视图目标检测结果的匹配方案，实现的双目检测结果对。
* 一种基于目标级别的双目匹配方法，实现了更好的深度预测的结果。
* 在双目匹配中使用了点云进行对深度进行监督，能够更好的还原目标的三维形状。
* 更快、更准。



## 算法流程

### 模型结构

![](https://glimg.oss-cn-shanghai.aliyuncs.com/test/20200714153110.png)
（途中，‘X’ 表示相乘操作）

算法的整体流程可以概括为：

1. 分别在双目输入的左右视图上进行 2D 目标检测，并基于 SSIM 对独立的检测结果进行匹配，得到一对双目的检测结果；
2. 在检测结果的 ROI 内，同时应用图像分割得到目标的 mask， 并输入stereo matching network 进行视差估计；
3. 将上述得到的视差转换至点云，并应用已有的基于点云的 3D目标检测器得到 3D检测结果。


### Object-Centric Stereo Matching

基于目标的的双目匹配是本文的核心。文章运用实例分割结果，只在目标的分割范围内进行视差估计，来去除背景对视差结果的影响。

#### 局部视差 Local Disparity

传统的视差，由左右视图中匹配上的像素点的像素坐标进行计算。本文的Local Disparity 定义为匹配的像素点到左右视图上各自 ROI 左边缘的横向距离。

根据传统视差，可以推算 Local Disparity 数学表达。

假定有一 ROI 图像，则各像素的局部横向坐标表示为：

$$
i_l = \left[ 
 \begin{matrix}
   0 & \cdots & w\\
   \vdots & \ddots & \vdots \\
   0 & \cdots & w
  \end{matrix} 
  \right]
$$

若 ROI 的左边缘对应原始图像的横向像素坐标为 $e_l$，则 $i_l$ 对应的全局横向像素坐标为：

$$x_l = e_l + i_l$$

根据全局的视差 $d_g$，则：

$$x_r = x_l - d_g$$
$$i_r = (x_r - e_r)*\frac{w}{w_b}$$

其中，$w_b$ 为右图 ROI 的原始宽度，进行视差计算时需要 resize 到与左右 ROI 相同的大小。

最终，local disparity 可以表达为：
$$d_l = i_l - i_r$$


模型通过学习，实现 local disparity 的预测，将局部视差按上述方法还原至全局误差，则测距结果为：

$$
D = \frac{f_x * b}{d_g^*}
$$

$d_g^*$ 为根据预测的局部视差，还原得到的全局视差。

#### 其他细节

* 视差估计网络：基于PSM-Net修改的模型进行目标级的local disparity 估计；
* 激光点云的监督：由于视差误差对深度的影响随着距离的增加是非线形。距离越大，相同视差的误差带来的深度误差越大。为更好的对深度进行学习，同时引入了激光对深度的预测结果进行监督。


## 实验结果

最后是实验结果分析。

KITTI 验证集上对 Car 的检测精度：

![](https://glimg.oss-cn-shanghai.aliyuncs.com/test/20200714183915.png)


KITTI 测试集上 Car 的检测精度：

![](https://glimg.oss-cn-shanghai.aliyuncs.com/test/20200714184014.png)

