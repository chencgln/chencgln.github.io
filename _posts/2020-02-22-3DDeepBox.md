---
layout: post
title:  "3D Bounding Box Estimation Using Deep Learning and Geometry"
date:   2020-02-22 18:00
categories: PaperReading 
tags: [Object Detection, Vision]
comments: true
toc: true
---

3D Bounding Box Estimation Using Deep Learning and Geometry 文章中提出了一种单目完成 3D 目标检测的方法。模型预测目标的三维尺寸、方向信息，并结合检测到的 2D BBox 的集合约束，对 3D BBox 进行求解，完成 3D 的目标检测。

该方法在 KITTI 数据集上评估了 3D orientation estimation 和 3D bounding boxes，都获得了较好的结果。同时在 Pascal 3D+ 数据集上，也验证了对于视点预测的准确性.

论文的创新点在于模型预测参数的选择以及基于参数进行目标 3D BBox 的求解思路。

**3D Bounding Box Estimation Using Deep Learning and Geometry**: [PDF](https://arxiv.org/abs/1612.00496)

参考代码：[Github](https://github.com/smallcorgi/3D-Deepbox)

## 主要贡献

* 提出了一种单目进行 3D 目标检测的方法，通过预测目标三维尺寸和朝向，并基于投影几何（projective geometry）求解目标姿态和 3D BBox；
* 使用了 discrete-continuous 的策略：**MultiBin regression**，实现目标朝向的预测；
* 引入了三种新的 3D BBox 评价指标；
* 算法同时在 Pascal 3D+ 数据集上验证了对**视点**预测的有效性.
 

<!-- 1. 直观地，先假设 2D BBox 的每一条边都对目标 3D BBox 8个角点的任一个建立上述方程，共有 $8^{4}=4096$ 个方程；
1. 由于目标，尤其对于车辆，3D BBox 一定是直立的，即底面和上表面的位置是确定的。因此针对 2D BBox 的上下边，可以减少一半的角点数量，因此方程数为：$8*8*4*4=1024$
2. 通常目标的 roll 角接近 $0^{o}$，2D BBox 的 $x_{min},x_{max}$/$y_{min},y_{max}$分别只与 3D BBox 的竖直边/水平边相关，即：$x_{min},x_{max}$ 对应边 $[\pm d_{x}/2,.,\pm d_{z}/2]，$y_{min},y_{max}$ 对应边 $[.,\pm d_{y}/2,\pm d_{z}/2]x_{min},x_{max}$，因此，对应的方程数更新为：$4^4=256$
3.  -->

## 实现细节

### 3D BBox 预测流程


文章提出一种利用预测的 2D BBox、目标朝向角和三维尺寸，来最小化误差求解目标的位置信息（目标中心点三维坐标） $T$ 的方法. 最终利用目标三维尺寸，中心坐标，朝向角就可以得到目标具体的 3D BBox。

文章的算法流程基于假设：目标 3D BBox 在图像上的 2D 投影应该外接于目标的 2D BBox。因此，2D BBox 的任一边 $(x_{min}, x_{max}, y_{min}, y_{max})$ 应与 3D BBox 的其中一个顶点投影的 $x$ 或 $y$ 对应。

设如下参数：

* 目标中心点坐标：$T = [t_{x}, t_{y}, t_{z}]^{T}$
* 目标三维尺寸：$D = [d_{x}, d_{y}, d_{z}]$
* 目标朝向角：$R(\theta ,\phi ,\alpha)$
* 目标 3D BBox 的各个角点由 $T$ 和 $D$ 得到，可表示为：$[X_{1}=d_{x}/2, -d_{y}/2, d_{z}/2], X_{2}=[d_{x}/2, -d_{y}/2, d_{z}/2], ... , X_{8}=[d_{x}/2, -d_{y}/2, d_{z}/2]$


根据透视理论，可假设当 x_{min} 对应顶点 $[d_{x}/2, -d_{y}/2, d_{z}/2]$ 时，有透视关系：

$$x_{min} = \left( K [R\quad T] \left[\begin{array}{c}
d_{x}/2\\
-d_{y}/2\\
d_{z}/2\\
1
\end{array}
\right]\right)_{x}$$

直观地，2D BBox 的每一条边都可以对目标 3D BBox 8个角点的任一个建立上述方程，共有 $8^{4}=4096$ 个方程；

通过以下约束可减少求解的范围：

1. 由于目标，尤其对于车辆，3D BBox 一定是直立的，即底面和上表面的位置是确定的。
2. 通常目标的 roll 角接近 $0^{o}$，2D BBox 的 $x_{min},x_{max}$/$y_{min},y_{max}$分别只与 3D BBox 的竖直边/水平边相关，即：$x_{min},x_{max}$ 对应边 $[\pm d_{x}/2,.,\pm d_{z}/2]，$y_{min},y_{max}$ 对应边 $[.,\pm d_{y}/2,\pm d_{z}/2]x_{min},x_{max}$
3. 由于在 KITTI 数据集上，pitch 和 roll 角假定为零

最后，可以得到 2D BBox 与 3D BBox 的角点对应关系：

* $x_{min}$ --> $[\pm d_{x}/2,.,\pm d_{z}/2]$
* $x_{max}$ --> $[\pm d_{x}/2,.,\pm d_{z}/2]$
* $y_{min}$ --> $[.,d_{y}/2,.,\pm d_{z}/2]$
* $y_{max}$ --> $[.,-d_{y}/2,\pm d_{z}/2]$

共 64 种映射关系。

由模型得到的2D BBox、目标朝向角和三维尺寸，依据上述约束条件，即可最小化误差来对目标的中心点 $T$ 进行求解。具体的求解方法可参考文章的补充材料: [http://bit.ly/2oYMpuw](http://bit.ly/2oYMpuw)

### 模型结构

论文提出的模型输出为检测目标的三维尺寸和朝向来实现，通过后处理即可求解目标的 3D BBox。模型的结构可以表示为：

![](https://note.youdao.com/yws/public/resource/85316e5cb1fff56c44995b8d7939e13b/xmlnote/WEBRESOURCEefca26d3649799e69cfef93bdc0be82f/916)


### MultiBin Orientation Estimation

待预测的目标朝向，可以分为全局方向 $\theta$ 和 目标的局部方向: $\theta_{l}$ ，二者可以互相转换，转换的原理参考下图（左）。

|||
:-:|:-:
![](https://note.youdao.com/yws/public/resource/85316e5cb1fff56c44995b8d7939e13b/xmlnote/WEBRESOURCEe47ed7624456631c0d7b0a989b49ed4b/910)|![](https://note.youdao.com/yws/public/resource/85316e5cb1fff56c44995b8d7939e13b/xmlnote/WEBRESOURCE4103300cebc7309b6407296ab7774a97/913)


考虑对于一个目标，当保持 $\theta$ 不变进行运动时，在图像上观察到的 $\theta_{l}$ 是随距离变化的（上图右）。因此，基于目标检测的局部图像特征，$\theta_{l}$ 应是更适合用来预测的值。并可以利用预测的 $\theta_{l}$ 来计算 $\theta$。

对于角度的回归，文章采用了 MultiBin 的方法实现了离散地求解。首先将角度划分为 $n$ 个有交集的 bins，模型通过预测各个 bin 的概率和回归 一个偏移量，来得到最终的角度结果。对一 $i^{th}$ bin，其预测值包括：$(c_{i}, cos(\Delta \theta_{i}), sin(\Delta \theta_{i}))$。

另外在 $cos(\Delta \theta_{i}), sin(\Delta \theta_{i})$ 的回归中添加了 L2 正则化得到更精确的角度结果。 

#### Loss 定义

整体 loss 可以总结为：

$$L_{\theta} = L_{conf} + \omega * L_{loc}$$

对于GT：$\theta ^{*}$
* $L_{conf}$: Softmax Loss
* $L_{loc}$，取包含 $\theta ^{*}$ 的 $n_{\theta ^{*}}$ 个 bins：

$$L_{loc} = - \frac{1}{n_{\theta ^{*}}}\sum cos(\theta ^{*}-c_{i}-\Delta \theta _{i})$$

### Object Dimensions

目标的三维尺寸是基于 L2 loss 进行回归的。通过计算训练集上不同类别对应的平均尺寸，然后回归各个目标相对于其各维度平均尺寸的残差。因此 Loss 的方程可以表示为：

$$L_{dim} = \frac{1}{n}\sum (D^{*}-\overline{D}-\delta)^{2}$$

最终，整体的 Loss 可以总结为：

$$L = \alpha L_{dims} + L_{\theta}$$

## 实验和结果

![](
https://note.youdao.com/yws/public/resource/85316e5cb1fff56c44995b8d7939e13b/xmlnote/WEBRESOURCE85d3d23259183340295924bebbce6634/918)

### 示例

KITTI 数据上对应的 2D 和 3D BBox 结果：

![](https://note.youdao.com/yws/public/resource/85316e5cb1fff56c44995b8d7939e13b/xmlnote/WEBRESOURCE118b61b3470ee4b09aad4c76656635bd/920)
